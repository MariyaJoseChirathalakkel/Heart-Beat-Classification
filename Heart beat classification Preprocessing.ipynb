{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Spliting the normal and abnormal audio files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import the necessary packages\n",
    "\n",
    "from glob import glob\n",
    "import ntpath\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from scipy.io import wavfile\n",
    "from tqdm import tqdm\n",
    "from scipy.io import wavfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#After putting all the audios into a single folder read them into the python file\n",
    "\n",
    "audios=\"C:/Users/Admin/Desktop/Datapirates/audio training data/all audio\"\n",
    "audio_files=glob(audios + '/*.wav')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create an empty list and put all the audio names into the list\n",
    "\n",
    "filename=[]\n",
    "for i in audio_files:\n",
    "    filename.append(ntpath.basename(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# slelect the csv file where the audio classes are given\n",
    "\n",
    "data=pd.read_csv(\"C:/Users/Admin/Desktop/Datapirates/audio training data/normal audio with extension.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#make a list f audios which are labeled -1 \n",
    "\n",
    "d1=list(data['normal data(-1)'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# taking the auio files from the list d1 and saving them into another folder in the system, this will be the normal audio files  \n",
    "\n",
    "for i in  tqdm(d1):\n",
    "    rate, s = wavfile.read(\"C:/Users/Admin/Desktop/Datapirates/audio training data/all audio/\"+i)\n",
    "    wavfile.write(\"C:/Users/Admin/Desktop/Datapirates/audio training data/normal/\"+i,rate,s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the audios which are labeld with 1 into another folder and this will be the abnormal audio files\n",
    "data2=pd.read_csv(\"C:/Users/Admin/Desktop/Datapirates/audio training data/abnormal2 with wav.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create another list d2 \n",
    "#Read the files in d2 from the all audio files\n",
    "#Write them into a new file\n",
    "d2=list(data2['abnormal(1)'])\n",
    "for i in  tqdm(d2):\n",
    "    rate, s = wavfile.read(\"C:/Users/Admin/Desktop/Datapirates/audio training data/all audio/\"+i)\n",
    "    wavfile.write(\"C:/Users/Admin/Desktop/Datapirates/audio training data/abnormal/\"+i,rate,s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step2: Removing Noise from the audio data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing the necessary packages\n",
    "import pydub\n",
    "from pydub import AudioSegment\n",
    "from glob import glob\n",
    "from scipy.signal import butter,lfilter\n",
    "from scipy import signal\n",
    "from scipy.signal import filtfilt\n",
    "import numpy as np\n",
    "import librosa as lr\n",
    "from scipy.signal import hilbert\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "from glob import glob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Repeat the processes from PROCEDURE1 to PROCEDURE2 for normal and abnormal data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#PROCEDURE 1\n",
    "#Read the data\n",
    "data_dir=r\"C:\\Users\\admin\\Desktop\\Datapirates\\normal and abnormal\\abnormal\"\n",
    "audio_files=glob(data_dir + '/*.wav')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#PROCEDURE 2\n",
    "# Read the audio files with a sample rate 4000 and append the amplitude arrays into a dictionary\n",
    "signdict={}\n",
    "for audio in audio_files:\n",
    "    array,frq=lr.core.load(audio,sr=4000)\n",
    "    signdict[audio]=array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#PROCEDURE 3\n",
    "# Take the amplitude values between 25khz to 400 khz sing a 4th order buttoroth bandpass filter.\n",
    "# The amplitude values which exceeds these two limit points will be noise\n",
    "butterout={}\n",
    "for key,array in signdict.items():\n",
    "    N=4\n",
    "    nyq=0.5*4000\n",
    "    low= 25 / nyq\n",
    "    high= 400 / nyq\n",
    "    b,a=signal.butter(N,[low,high],btype='band')\n",
    "    outs=signal.filtfilt(b,a,array)\n",
    "    output=abs(outs)\n",
    "    butterout[key]=output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#PROCEDURE 4\n",
    "#Split the audios into 5 seconds \n",
    "#This will help you to increase your samples\n",
    "start=0\n",
    "end=0\n",
    "interval=5000\n",
    "counter=1\n",
    "emplist=[]\n",
    "for key,audio in butterout.items():\n",
    "    n=len(audio)\n",
    "    for i in range(0,n,interval):\n",
    "        if i == 0:\n",
    "            start=0\n",
    "            end=interval\n",
    "        else:\n",
    "            start=end\n",
    "            end=start+interval\n",
    "        if end >= n:\n",
    "            end=n\n",
    "        chunk=audio[start:end]\n",
    "        emplist.append(chunk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#PROCEDURE 5\n",
    "#Find the mean values of each array \n",
    "#Repalce the values wich are three times greater than the mean value\n",
    "\n",
    "for i in range(len(emplist)):\n",
    "    mean=emplist[i].mean()\n",
    "    for j in range(len(emplist[i])):\n",
    "        if emplist[i][j] >= 3*mean:\n",
    "            emplist[i][j]=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#PROCEDURE 6\n",
    "# Perform hilbert transform on the data to rotate it 90 degree\n",
    "b=[]\n",
    "def hilber(i):\n",
    "    c=hilbert(i)\n",
    "    b.append(c)\n",
    "    return b\n",
    "for i in emplist:\n",
    "    h=hilber(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#PROCEDURE 7\n",
    "#Get the absolute values of the amplitude from hilbrt transform \n",
    "ampl=[]\n",
    "def amplitude(j):\n",
    "    amp=np.abs(j)\n",
    "    ampl.append(amp)\n",
    "    return ampl\n",
    "for j in h:\n",
    "    k=amplitude(j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#PROCEDURE 8\n",
    "# Make the spctrogram of the images and save it as a jpg image file\n",
    "def spectrogram(i):\n",
    "    plt.specgram(i,Fs=4000)\n",
    "    plt.savefig(str(j+1)+\".jpg\")\n",
    "    plt.close()\n",
    "j=0\n",
    "for i in k:\n",
    "    j=j+1\n",
    "    spectrogram(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#PROCEDURE 9\n",
    "#Use a crop function to cut the x and y axis labels \n",
    "data_dir=r\"C:\\Users\\admin\\Desktop\\Datapirates\\Spectrograms\\Spectrogram normal\"#Read the data\n",
    "image=glob(data_dir + '/*.jpg')\n",
    "\n",
    "#Defining the crop function\n",
    "def crop(i):\n",
    "    imageobject=Image.open(i)\n",
    "    croped=imageobject.crop((54,35,390,253))\n",
    "    croped.save(str(path)+\".jpg\")\n",
    "    \n",
    "#Run the crop function on the data\n",
    "path=1\n",
    "for i in image:\n",
    "    path=path+1\n",
    "    crop(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### REPEAT THESE PROCESSES FOR VALIDATION DATA #####"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Spliting data into train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import the packages\n",
    "import os\n",
    "import random\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create empty files to store the file names before and after spliting\n",
    "filenames=[]\n",
    "train_filenames=[]\n",
    "test_filenames=[]\n",
    "filenames1=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read the file \n",
    "paths=\"C:/Users/admin/Desktop/Datapirates/Cropped Spectrograms normal and abnormal/crpped normal\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the files in 80:20 ratio \n",
    "for j in os.listdir(paths):\n",
    "    filenames1.append(paths+\"/\"+j)\n",
    "    filenames1.sort()  # make sure that the filenames have a fixed order before shuffling\n",
    "    random.seed(230)\n",
    "    random.shuffle(filenames1) # shuffles the ordering of filenames (deterministic given the chosen seed)\n",
    "split_1 = int(0.8 * (len(filenames1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Save the test and train data into two variables\n",
    "train_filenames +=(filenames1[:split_1])\n",
    "test_filenames += (filenames1[split_1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save test normal train normal test abnormal and train abnormal into different folders by changing the folder paths\n",
    "dst_dir=\"C:/Users/admin/Desktop/Datapirates/Test/Normal\"\n",
    "for i in test_filenames:\n",
    "    shutil.copy(i , dst_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### PREPROCESSING ON  SPECTROGRAM IMAGES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the packages which are necessary\n",
    "import os\n",
    "import cv2\n",
    "from sklearn.utils import shuffle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Resizing the images\n",
    "def lo(image):\n",
    "    image = image/255\n",
    "    return image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reading Train,Test and Validation images for inputing into model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reading images from the Training dataset\n",
    "tx = []\n",
    "ty = []\n",
    "#tz = []\n",
    "\n",
    "dir_list=\"C:/Users/admin/Desktop/Datapirates/Train\" \n",
    "for directory in os.listdir(dir_list):\n",
    "    for filename in os.listdir(dir_list + '/' + directory):\n",
    "        #tz.append(filename) \n",
    "        \n",
    "        image = cv2.imread(dir_list + '/' + directory + '/' + filename)\n",
    "        image = lo(image)\n",
    "        image = cv2.resize(image,dsize=(32,32))\n",
    "        \n",
    "        \n",
    "       \n",
    "        \n",
    "        tx.append(image)\n",
    "        \n",
    "        ###labelling\n",
    "        if directory == 'Normal':\n",
    "            ty.append(1)\n",
    "        else:\n",
    "            ty.append(0)  \n",
    "        \n",
    "xtrain=np.array(tx) \n",
    "ytrain=np.array(ty)\n",
    "\n",
    "xtrain,ytrain=shuffle(xtrain,ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xtrain.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ytrain.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reading images from the testing data set\n",
    "x1 = []\n",
    "y1 = []\n",
    "\n",
    "dir_list=\"C:/Users/admin/Desktop/Datapirates/Test\"   \n",
    "for directory in os.listdir(dir_list):\n",
    "    for filename in os.listdir(dir_list + '/' + directory):\n",
    "        #z1.append(filename) \n",
    "        \n",
    "        image = cv2.imread(dir_list + '/' + directory + '/' + filename)\n",
    "        image=lo(image)\n",
    "        image = cv2.resize(image,dsize=(32,32))\n",
    "        \n",
    "        x1.append(image)\n",
    "        \n",
    "        if directory == 'Normal':\n",
    "            y1.append(1)\n",
    "        else:\n",
    "            y1.append(0) \n",
    "            \n",
    "\n",
    "xtest=np.array(x1)\n",
    "ytest=np.array(y1)\n",
    "xtest,ytest=shuffle(xtest,ytest)     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xtest.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ytest.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reading images from the validation dataset\n",
    "val=[]\n",
    "file=[]\n",
    "\n",
    "\n",
    "dir_list=\"C:/Users/admin/Desktop/Datapirates/Validation cropped\"   \n",
    "for directory in os.listdir(dir_list):\n",
    "    for filename in os.listdir(dir_list + '/' + directory):\n",
    "        #file.append(filename) \n",
    "        \n",
    "        image = cv2.imread(dir_list + '/' + directory + '/' + filename)\n",
    "        image=lo(image)\n",
    "        image=cv2.resize(image,dsize=(32,32))\n",
    "        \n",
    "        \n",
    "        val.append(image)\n",
    "        \n",
    "        \n",
    "        if directory == 'Normal':\n",
    "            file.append(1)\n",
    "        else:\n",
    "            file.append(0)\n",
    "            \n",
    "xval=np.array(val)\n",
    "yval=np.array(file)\n",
    "xval,yval=shuffle(xval,yval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xval.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yval.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xtrain=np.array(tx)\n",
    "ytrain=np.array(ty)\n",
    "ytest=np.array(y1)\n",
    "xtest=np.array(x1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ytrain1 = to_categorical(ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ytrain1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xtrain = xtrain.astype('float32')\n",
    "xtest = xtest.astype('float32')\n",
    "xval = xval.astype('float32')\n",
    "\n",
    "# Transform lables to one-hot encoding\n",
    "ytrain = to_categorical(ytrain)\n",
    "ytest = to_categorical(ytest)\n",
    "yval=to_categorical(yval)\n",
    "# Reshape the dataset into 4D array\n",
    "xtrain = xtrain.reshape(xtrain.shape[0], 32,32,3)\n",
    "xtest = xtest.reshape(xtest.shape[0], 32,32,3)\n",
    "xval = xval.reshape(xval.shape[0], 32,32,3)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
